{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8a62cb-e60a-4a4b-9d89-122bcf53d2f7",
   "metadata": {},
   "source": [
    "## Modifying Residual Connections\n",
    "\n",
    "Testing code for accessing the representation at a given layer **before applying the residual connection**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5ba34b4-8c3e-4351-8fc8-f2474f4c7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertLayer\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertConfig\n",
    "\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09652ee8-798b-4386-af05-a8209a390cd9",
   "metadata": {},
   "source": [
    "## ChatGPT Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "330eec49-8495-4206-8612-28b50b256dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-Residual Output for Layer 5\n",
      "tensor([[ 0.0367, -0.3417, -0.3950,  ...,  0.0788,  0.1991,  0.3832],\n",
      "        [ 0.9718,  0.1975,  0.7590,  ...,  0.6820,  0.1647, -0.4499],\n",
      "        [ 0.1348,  0.4053,  0.0572,  ..., -0.2338, -0.1639,  0.6239],\n",
      "        ...,\n",
      "        [-0.2164, -1.4882,  0.8183,  ..., -0.1463, -0.0400,  0.0578],\n",
      "        [ 0.3149, -0.7261, -0.5962,  ...,  0.0103,  0.0065,  0.6139],\n",
      "        [ 0.0138, -0.0125, -0.0064,  ...,  0.0026, -0.0205, -0.0142]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Hidden State Output for Layer 5\n",
      "tensor([[ 0.0839, -0.9179, -0.5961,  ...,  0.0639,  0.3273,  0.3681],\n",
      "        [ 0.7318, -0.1368,  1.1241,  ...,  0.6588, -0.2409, -0.5797],\n",
      "        [-0.1293,  0.5957,  0.2409,  ..., -0.5293, -0.3646,  0.5766],\n",
      "        ...,\n",
      "        [-0.3583, -1.9956,  0.9719,  ..., -0.1385,  0.1476, -0.3508],\n",
      "        [ 0.3562, -1.0461, -0.9223,  ...,  0.0445, -0.2199,  0.5077],\n",
      "        [ 0.0170, -0.0387, -0.0153,  ...,  0.0079, -0.0167, -0.0436]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Are the outputs equal? False\n",
      "\n",
      "Pre-Residual Output for Layer 5\n",
      "tensor([[ 0.0626, -0.0636, -0.1883,  ...,  0.0645,  0.1497,  0.0104],\n",
      "        [ 0.1299, -0.0569, -0.1732,  ...,  0.0170, -0.0032, -0.1608],\n",
      "        [ 0.0231,  0.2311, -0.0455,  ..., -0.1979, -0.0427,  0.0067],\n",
      "        ...,\n",
      "        [-0.1986, -0.0290,  0.1431,  ..., -0.0847,  0.1939,  0.1479],\n",
      "        [-0.3089,  0.0434, -0.5649,  ..., -0.1293,  0.0199,  0.1982],\n",
      "        [-0.0224,  0.1020, -0.0129,  ..., -0.0160, -0.0384,  0.0490]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#### ChatGPT version\n",
    "# Define a custom model class\n",
    "class CustomBertModel(BertModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        # Call the original forward method to get the standard outputs\n",
    "        outputs = super().forward(*args, **kwargs)\n",
    "        \n",
    "        # Extract hidden states from the original forward pass\n",
    "        hidden_states = outputs.hidden_states  # List of hidden states at each layer\n",
    "        \n",
    "        # Lists to store pre-residual and post-residual outputs of each layer\n",
    "        pre_residual_outputs = []\n",
    "        post_residual_outputs = []\n",
    "        \n",
    "        # Iterate through each layer to compute pre-residual and post-residual outputs\n",
    "        for i, layer in enumerate(self.encoder.layer):\n",
    "            # Compute self-attention output (before adding residual connection)\n",
    "            self_attention_outputs = layer.attention(hidden_states[i], output_attentions=False)\n",
    "            attention_output = self_attention_outputs[0]\n",
    "            pre_residual_attention_output = attention_output  # Save pre-residual attention output\n",
    "            \n",
    "            # Apply attention output with residual connection and normalization\n",
    "            attention_output = layer.attention.output.LayerNorm(attention_output + hidden_states[i])\n",
    "            \n",
    "            # Compute feedforward output (before adding residual connection)\n",
    "            intermediate_output = layer.intermediate(attention_output)\n",
    "            layer_output = layer.output.dense(intermediate_output)\n",
    "            pre_residual_layer_output = layer_output  # Save pre-residual layer output\n",
    "            \n",
    "            # Apply feedforward output with residual connection and normalization\n",
    "            layer_output = layer.output.LayerNorm(layer_output + attention_output)\n",
    "            \n",
    "            # Store the pre-residual and post-residual outputs\n",
    "            pre_residual_outputs.append(pre_residual_layer_output)\n",
    "            post_residual_outputs.append(layer_output)\n",
    "        \n",
    "        # Return the standard outputs, pre-residual outputs, and post-residual outputs\n",
    "        return outputs, pre_residual_outputs, post_residual_outputs\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = CustomBertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "\n",
    "# Tokenize the input text\n",
    "input_text = \"Hello, how are you?\"\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "# Forward pass\n",
    "outputs, pre_residual_outputs, post_residual_outputs = model(**inputs)\n",
    "\n",
    "# Extract the post-residual outputs and hidden states for a specific layer\n",
    "layer_index = 5  # Example layer index\n",
    "post_residual_layer_output = post_residual_outputs[layer_index][0]\n",
    "pre_residual_layer_output = pre_residual_outputs[layer_index][0]\n",
    "hidden_state_layer_output = outputs.hidden_states[layer_index + 1][0]  # hidden_states includes embedding layer as the first element\n",
    "\n",
    "# Compare the post-residual outputs to the hidden states\n",
    "print(\"Post-Residual Output for Layer\", layer_index)\n",
    "print(post_residual_layer_output)\n",
    "\n",
    "print(\"\\nHidden State Output for Layer\", layer_index)\n",
    "print(hidden_state_layer_output)\n",
    "\n",
    "# Check if they are equal\n",
    "print(\"\\nAre the outputs equal?\", torch.allclose(post_residual_layer_output, hidden_state_layer_output, atol=1e-6))\n",
    "\n",
    "# Also print the pre-residual output for clarity\n",
    "print(\"\\nPre-Residual Output for Layer\", layer_index)\n",
    "print(pre_residual_layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68581bbb-4f87-4356-9f65-8df6a80cc7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between the post/hidden tensors: 0.9362243522476544\n",
      "Pearson Correlation between the pre/hidden tensors: 0.281897231078784\n",
      "Pearson Correlation between the pre/post tensors: 0.2666938847810285\n"
     ]
    }
   ],
   "source": [
    "# Compute the overall correlation between the two tensors using scipy\n",
    "post_residual_flat = post_residual_layer_output.flatten().detach().numpy()\n",
    "hidden_state_flat = hidden_state_layer_output.flatten().detach().numpy()\n",
    "\n",
    "correlation, _ = pearsonr(post_residual_flat, hidden_state_flat)\n",
    "print(\"Pearson Correlation between the post/hidden tensors:\", correlation)\n",
    "\n",
    "pre_residual_flat = pre_residual_layer_output.flatten().detach().numpy()\n",
    "\n",
    "correlation, _ = pearsonr(pre_residual_flat, hidden_state_flat)\n",
    "print(\"Pearson Correlation between the pre/hidden tensors:\", correlation)\n",
    "\n",
    "correlation, _ = pearsonr(pre_residual_flat, post_residual_flat)\n",
    "print(\"Pearson Correlation between the pre/post tensors:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0977cc5d-5e23-4fc9-8d8a-36639b704015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of post/hidden elements with Same Sign: 0.8889973759651184\n",
      "Proportion of pre/hidden elements with Same Sign: 0.60009765625\n",
      "Proportion of pre/post elements with Same Sign: 0.6072590947151184\n"
     ]
    }
   ],
   "source": [
    "# Check if the two tensors have the same sign for each element\n",
    "same_sign = torch.sign(post_residual_layer_output) == torch.sign(hidden_state_layer_output)\n",
    "\n",
    "# Compute the proportion of elements with the same sign\n",
    "proportion_same_sign = torch.mean(same_sign.float())\n",
    "print(\"Proportion of post/hidden elements with Same Sign:\", proportion_same_sign.item())\n",
    "\n",
    "same_sign = torch.sign(pre_residual_layer_output) == torch.sign(hidden_state_layer_output)\n",
    "\n",
    "# Compute the proportion of elements with the same sign\n",
    "proportion_same_sign = torch.mean(same_sign.float())\n",
    "print(\"Proportion of pre/hidden elements with Same Sign:\", proportion_same_sign.item())\n",
    "\n",
    "same_sign = torch.sign(pre_residual_layer_output) == torch.sign(post_residual_layer_output)\n",
    "\n",
    "# Compute the proportion of elements with the same sign\n",
    "proportion_same_sign = torch.mean(same_sign.float())\n",
    "print(\"Proportion of pre/post elements with Same Sign:\", proportion_same_sign.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9427753-fa26-4099-b1e4-a17b3fee1d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post residual shape: torch.Size([8, 768])\n",
      "Pre residual shape: torch.Size([8, 768])\n",
      "Hidden state shape: torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Post residual shape:\", post_residual_layer_output.shape)\n",
    "print(\"Pre residual shape:\", pre_residual_layer_output.shape)\n",
    "print(\"Hidden state shape:\", hidden_state_layer_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70f14c-6a3b-485d-b0de-73809d2c73dc",
   "metadata": {},
   "source": [
    "## Claude Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea4d67bb-611f-45fb-bd39-357ce00690fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Pre-residual shape: torch.Size([1, 5, 768])\n",
      "Post-residual shape: torch.Size([1, 5, 768])\n",
      "Current hidden state shape: torch.Size([1, 5, 768])\n",
      "Next hidden state shape: torch.Size([1, 5, 768])\n",
      "\n",
      "Comparisons:\n",
      "Post-residual == Next hidden state: False\n",
      "Current hidden state == Input to layer: True\n",
      "Pre-residual == Post-residual: False\n",
      "Mean difference (Post - Pre): 0.0108\n",
      "Std of difference (Post - Pre): 0.9014\n",
      "\n",
      "\n",
      "\n",
      "Correlations:\n",
      "Pearson Correlation between the post/next-hidden tensors: 0.903245657406737\n",
      "Pearson Correlation between the post/current-hidden tensors: 0.6284135594108322\n",
      "Pearson Correlation between the pre/next-hidden tensors: 0.42370215965868574\n",
      "Pearson Correlation between the pre/current-hidden tensors: -0.13993228592411655\n",
      "Pearson Correlation between the pre/post tensors: 0.3484587061685561\n",
      "\n",
      "\n",
      "Layer 11:\n",
      "Pre-residual shape: torch.Size([1, 5, 768])\n",
      "Post-residual shape: torch.Size([1, 5, 768])\n",
      "Current hidden state shape: torch.Size([1, 5, 768])\n",
      "Next hidden state shape: torch.Size([1, 5, 768])\n",
      "\n",
      "Comparisons:\n",
      "Post-residual == Next hidden state: False\n",
      "Current hidden state == Input to layer: True\n",
      "Pre-residual == Post-residual: False\n",
      "Mean difference (Post - Pre): -0.0119\n",
      "Std of difference (Post - Pre): 0.5150\n",
      "\n",
      "\n",
      "\n",
      "Correlations:\n",
      "Pearson Correlation between the post/next-hidden tensors: 0.9317042850244381\n",
      "Pearson Correlation between the post/current-hidden tensors: 0.9358700728639344\n",
      "Pearson Correlation between the pre/next-hidden tensors: 0.20748496903251235\n",
      "Pearson Correlation between the pre/current-hidden tensors: -0.07044417548618223\n",
      "Pearson Correlation between the pre/post tensors: 0.07907596162168465\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class CustomBertModel(BertModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None):\n",
    "        # Call the original forward method to get the standard outputs\n",
    "        outputs = super().forward(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            output_hidden_states=True,  # Enable output of all hidden states\n",
    "        )\n",
    "        \n",
    "        # Extract hidden states from the original forward pass\n",
    "        hidden_states = outputs.hidden_states  # List of hidden states at each layer\n",
    "        \n",
    "        # Lists to store pre-residual and post-residual outputs of each layer\n",
    "        pre_residual_outputs = []\n",
    "        post_residual_outputs = []\n",
    "        \n",
    "        # Iterate through each layer to compute pre-residual and post-residual outputs\n",
    "        for i, layer in enumerate(self.encoder.layer):\n",
    "            # Compute self-attention output (before adding residual connection)\n",
    "            self_attention_outputs = layer.attention(hidden_states[i], attention_mask, head_mask[i] if head_mask is not None else None, output_attentions=False)\n",
    "            attention_output = self_attention_outputs[0]\n",
    "            \n",
    "            # Apply attention output with residual connection and normalization\n",
    "            attention_output = layer.attention.output.LayerNorm(attention_output + hidden_states[i])\n",
    "            \n",
    "            # Compute feedforward output (before adding residual connection)\n",
    "            intermediate_output = layer.intermediate(attention_output)\n",
    "            layer_output = layer.output.dense(intermediate_output)\n",
    "            pre_residual_layer_output = layer_output  # Save pre-residual layer output\n",
    "            \n",
    "            # Apply feedforward output with residual connection and normalization\n",
    "            layer_output = layer.output.LayerNorm(layer_output + attention_output)\n",
    "            \n",
    "            # Store the pre-residual and post-residual outputs\n",
    "            pre_residual_outputs.append(pre_residual_layer_output)\n",
    "            post_residual_outputs.append(layer_output)\n",
    "        \n",
    "        # Create a new output object with all the original outputs plus our new pre_residual and post_residual outputs\n",
    "        new_outputs = BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            pooler_output=outputs.pooler_output,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            attentions=outputs.attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "        )\n",
    "        \n",
    "        new_outputs.pre_residual_outputs = pre_residual_outputs\n",
    "        new_outputs.post_residual_outputs = post_residual_outputs\n",
    "\n",
    "        return new_outputs\n",
    "\n",
    "# Usage example\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = CustomBertModel.from_pretrained('bert-base-uncased', config=config)\n",
    "\n",
    "# Forward pass\n",
    "input_ids = torch.tensor([[1, 2, 3, 4, 5]])\n",
    "outputs = model(input_ids)\n",
    "\n",
    "# Compare outputs\n",
    "def compare_outputs(layer_idx):\n",
    "    pre_residual = outputs.pre_residual_outputs[layer_idx]\n",
    "    post_residual = outputs.post_residual_outputs[layer_idx]\n",
    "    current_hidden_state = outputs.hidden_states[layer_idx]  # This is the input to the current layer\n",
    "    next_hidden_state = outputs.hidden_states[layer_idx + 1]  # This is the output of the current layer\n",
    "\n",
    "    print(f\"Layer {layer_idx}:\")\n",
    "    print(f\"Pre-residual shape: {pre_residual.shape}\")\n",
    "    print(f\"Post-residual shape: {post_residual.shape}\")\n",
    "    print(f\"Current hidden state shape: {current_hidden_state.shape}\")\n",
    "    print(f\"Next hidden state shape: {next_hidden_state.shape}\")\n",
    "    \n",
    "    print(\"\\nComparisons:\")\n",
    "    print(f\"Post-residual == Next hidden state: {torch.allclose(post_residual, next_hidden_state, atol=1e-5)}\")\n",
    "    print(f\"Current hidden state == Input to layer: {torch.allclose(current_hidden_state, outputs.hidden_states[layer_idx], atol=1e-5)}\")\n",
    "    print(f\"Pre-residual == Post-residual: {torch.allclose(pre_residual, post_residual, atol=1e-5)}\")\n",
    "    print(f\"Mean difference (Post - Pre): {(post_residual - pre_residual).mean().item():.4f}\")\n",
    "    print(f\"Std of difference (Post - Pre): {(post_residual - pre_residual).std().item():.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"\\nCorrelations:\")\n",
    "    # Compute the overall correlation between the two tensors using scipy\n",
    "    post_residual_flat = post_residual.flatten().detach().numpy()\n",
    "    next_hidden_state_flat = next_hidden_state.flatten().detach().numpy()\n",
    "    current_hidden_state_flat = current_hidden_state.flatten().detach().numpy()\n",
    "    pre_residual_flat = pre_residual.flatten().detach().numpy()\n",
    "    \n",
    "    post_next_hidden_correlation, _ = pearsonr(post_residual_flat, next_hidden_state_flat)\n",
    "    post_current_hidden_correlation, _ = pearsonr(post_residual_flat, current_hidden_state_flat)\n",
    "    pre_post_correlation, _ = pearsonr(post_residual_flat, pre_residual_flat)\n",
    "    pre_next_hidden_correlation, _ = pearsonr(pre_residual_flat, next_hidden_state_flat)\n",
    "    pre_current_hidden_correlation, _ = pearsonr(pre_residual_flat, current_hidden_state_flat)\n",
    "    \n",
    "    print(\"Pearson Correlation between the post/next-hidden tensors:\", post_next_hidden_correlation)\n",
    "    print(\"Pearson Correlation between the post/current-hidden tensors:\", post_current_hidden_correlation)\n",
    "    print(\"Pearson Correlation between the pre/next-hidden tensors:\", pre_next_hidden_correlation)\n",
    "    print(\"Pearson Correlation between the pre/current-hidden tensors:\", pre_current_hidden_correlation)\n",
    "    print(\"Pearson Correlation between the pre/post tensors:\", pre_post_correlation)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Compare for first and last layer\n",
    "compare_outputs(0)  # First layer\n",
    "compare_outputs(len(outputs.hidden_states) - 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f75daff-5b16-4a5f-aa45-f63a9570f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seantrott/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage example\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = CustomBertModel.from_pretrained('bert-base-uncased', config=config)\n",
    "\n",
    "# Forward pass\n",
    "input_ids = torch.tensor([[1, 2, 3, 4, 5]])\n",
    "outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08efdba2-936c-42f2-951f-2b3b6f5430ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Intermediate (FFN) output shape: torch.Size([1, 5, 3072])\n",
      "Layer output shape: torch.Size([1, 5, 768])\n",
      "Hidden state shape: torch.Size([1, 5, 768])\n",
      "Attention output shape: torch.Size([1, 5, 768])\n",
      "\n",
      "Comparisons:\n",
      "Layer output == Hidden state: False\n",
      "Layer output == Attention output: False\n",
      "Intermediate output size vs Layer output size: 3072 vs 768\n",
      "\n",
      "\n",
      "Layer -1:\n",
      "Intermediate (FFN) output shape: torch.Size([1, 5, 3072])\n",
      "Layer output shape: torch.Size([1, 5, 768])\n",
      "Hidden state shape: torch.Size([1, 5, 768])\n",
      "Attention output shape: torch.Size([1, 5, 768])\n",
      "\n",
      "Comparisons:\n",
      "Layer output == Hidden state: False\n",
      "Layer output == Attention output: False\n",
      "Intermediate output size vs Layer output size: 3072 vs 768\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare outputs\n",
    "def compare_outputs(layer_idx):\n",
    "    intermediate_output = outputs.intermediate_outputs[layer_idx]\n",
    "    layer_output = outputs.layer_outputs[layer_idx]\n",
    "    hidden_state = outputs.hidden_states[layer_idx + 1]  # +1 because hidden_states includes the embedding layer\n",
    "    attention_output = outputs.attention_outputs[layer_idx]\n",
    "\n",
    "    print(f\"Layer {layer_idx}:\")\n",
    "    print(f\"Intermediate (FFN) output shape: {intermediate_output.shape}\")\n",
    "    print(f\"Layer output shape: {layer_output.shape}\")\n",
    "    print(f\"Hidden state shape: {hidden_state.shape}\")\n",
    "    print(f\"Attention output shape: {attention_output.shape}\")\n",
    "    \n",
    "    print(\"\\nComparisons:\")\n",
    "    print(f\"Layer output == Hidden state: {torch.allclose(layer_output, hidden_state)}\")\n",
    "    print(f\"Layer output == Attention output: {torch.allclose(layer_output, attention_output)}\")\n",
    "    print(f\"Intermediate output size vs Layer output size: {intermediate_output.shape[2]} vs {layer_output.shape[2]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Compare for first and last layer\n",
    "compare_outputs(0)  # First layer\n",
    "compare_outputs(-1)  # Last layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "090edec3-16e3-40bb-b61f-6750217728ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Transformation Analysis:\n",
      "Mean of intermediate output: -0.0204\n",
      "Std of intermediate output: 0.1660\n",
      "Mean of layer output: -0.0235\n",
      "Std of layer output: 0.6593\n",
      "Mean difference (layer - attention): 0.0065\n",
      "Std of difference (layer - attention): 0.7091\n",
      "\n",
      "\n",
      "Layer -1 Transformation Analysis:\n",
      "Mean of intermediate output: -0.0853\n",
      "Std of intermediate output: 0.1275\n",
      "Mean of layer output: -0.0082\n",
      "Std of layer output: 0.4493\n",
      "Mean difference (layer - attention): 0.0426\n",
      "Std of difference (layer - attention): 0.8514\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Additional analysis\n",
    "def analyze_layer_transformation(layer_idx):\n",
    "    intermediate_output = outputs.intermediate_outputs[layer_idx]\n",
    "    layer_output = outputs.layer_outputs[layer_idx]\n",
    "    attention_output = outputs.attention_outputs[layer_idx]\n",
    "\n",
    "    print(f\"Layer {layer_idx} Transformation Analysis:\")\n",
    "    print(f\"Mean of intermediate output: {intermediate_output.mean().item():.4f}\")\n",
    "    print(f\"Std of intermediate output: {intermediate_output.std().item():.4f}\")\n",
    "    print(f\"Mean of layer output: {layer_output.mean().item():.4f}\")\n",
    "    print(f\"Std of layer output: {layer_output.std().item():.4f}\")\n",
    "    print(f\"Mean difference (layer - attention): {(layer_output - attention_output).mean().item():.4f}\")\n",
    "    print(f\"Std of difference (layer - attention): {(layer_output - attention_output).std().item():.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Analyze transformations for first and last layer\n",
    "analyze_layer_transformation(0)  # First layer\n",
    "analyze_layer_transformation(-1)  # Last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e4edc-0887-4cbe-940c-d3f56d0240dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
