---
title: "Analysis of HuggingFace Models"
author: "Sean Trott and Pam Rivi√®re"
date: "November 20, 2024"
output:
  # pdf_document: 
  #      fig_caption: yes
  #     keep_md: yes
  #     keep_tex: yes
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dpi = 300, fig.format = "pdf")
```


```{r include=FALSE}
library(tidyverse)
library(lmtest)
library(forcats)
library(broom)
library(lme4)
library(viridis)
library(ggridges)
library(lmerTest)
library(ggrepel)

all_colors <- viridis::viridis(10, option = "mako")
my_colors <- all_colors[c(3, 5, 7)]  # Selecting specific colors from the palette
```

# Load Pythia data


```{r}
# setwd("/Users/seantrott/Dropbox/UCSD/Research/Ambiguity/SSD/entangled_meanings/src/analysis/")
# setwd("/Users/pamelariviere/Dropbox/Research/projects/entangled_meanings/src/analysis/")
directory_path <- "../../data/processed/rawc/pythia/distances/"
csv_files <- list.files(path = directory_path, pattern = "*.csv", full.names = TRUE)
csv_list <- csv_files %>%
  map(~ read_csv(.))
df_pythia_models <- bind_rows(csv_list)

table(df_pythia_models$mpath)

```



# Analyzing R2

## Best R2 by model size

```{r}
df_best_r2_scale = df_pythia_models %>% 
  filter(step == 143000) %>%
  filter(Layer >0 )%>%
  group_by(mpath, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%
  group_by(mpath, n_params) %>%
  slice_max(r2, n = 1) %>%
  mutate(mpath = str_remove(mpath, ".*?/"))

# Find the layer with the maximum R2 for each pythia model
df_best_r2_scale %>%
  arrange(n_params)

# Manuscript figure (Fig. 1b)
df_best_r2_scale %>%
  ggplot(aes(x = n_params,
             y = r2)) +
  #geom_line(size = 2, alpha = .3, linetype = "dotted") +
  geom_point(size = 6,
             alpha = .5) +
  geom_hline(yintercept = .64,##TODO: Calculate from scratch
             linetype = "dashed", color = "red",
             size = 4, alpha = .5) + 
  #geom_hline(yintercept = mean(df_r$estimate)**2, ### Human accuracy 
              #linetype = "dotted", color = "red",
             #size = 1.2, alpha = .5) +
  scale_x_log10() +
  geom_text_repel(aes(label=mpath), size=3) +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "Parameters (Log10)",
       y = "Maximum R2",
       color = "",
       shape = "") +
  theme_minimal() +
  # guides(color="none") +
  # scale_color_viridis(option = "mako", discrete=TRUE) +
  # scale_color_manual(values = my_colors)  +
  theme(text = element_text(size = 15),
        legend.position="bottom")


### Regression analysis
summary(lm(data = df_best_r2_scale,
           r2 ~ log10(n_params)))
```


## Residuals by model

```{r}
df_pythia_models_final = df_pythia_models %>%
  filter(step == 143000)

models <- by(df_pythia_models_final, df_pythia_models_final$mpath, function(subdata) {
  model <- lm(mean_relatedness ~ Distance * Layer, data = subdata)
  subdata$residuals <- residuals(model)
  return(subdata)
})

# Combine the results back into a single dataframe
results <- do.call(rbind, models)

results %>%
  ggplot(aes(x = residuals,
             fill = Same_sense)) +
  geom_density(alpha = .7, size = 0) +
  geom_vline(xintercept = 0, size = .6, linetype = "dashed") +
  theme_minimal() +
  # scale_fill_viridis(option = "mako", discrete=TRUE) +
  theme(text = element_text(size = 15),
        legend.position="bottom") +
  scale_fill_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15))  +
  labs(x = "Residuals (Relatedness ~ Distance * Layer)",
       fill = "") +
  facet_wrap(~reorder(mpath, n_params))


results %>%
  group_by(mpath, n_params, Same_sense) %>%
  summarise(mean_resid = mean(residuals),
            se_resid = sd(residuals)/sqrt(n())) %>%
  ggplot(aes(x = n_params,
             y = mean_resid,
             color = Same_sense)) +
  geom_point(size = 3, alpha = .6) +
  # coord_flip() +
  geom_hline(yintercept = 0, linetype = "dotted") +
  geom_errorbar(aes(ymin = mean_resid - 2*se_resid, 
                    ymax = mean_resid + 2*se_resid), 
                width=.2) + 
                # position=position_dodge(.9)) +
  scale_x_log10() +
  labs(x = "Parameters",
       y = "Residual Error",
       color = "") +
  # geom_text_repel(aes(label=mpath), size=3) +
  theme_minimal() +
  scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15))  +
  theme(text = element_text(size = 15),
        legend.position="bottom")


```




## R2 by layer, final step

```{r}
df_best_r2_layer = df_pythia_models %>% 
  filter(step == 143000) %>%
  filter(Layer > 0) %>%
  group_by(mpath, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%  
  mutate(model = sub("^EleutherAI/", "", mpath)) %>%
  group_by(model) %>%
  mutate(max_layer = max(Layer),
         prop_layer = Layer / max_layer) %>%
  ### Scale for interpreting the coefficients more easily
  mutate(prop_layer_scaled = scale(prop_layer)) %>%
  ungroup()

df_best_r2_layer %>%
  ggplot(aes(x = Layer,
             y = r2,
             color = reorder(model, n_params))) +
  #geom_point(size = 3, alpha = .7) +
  geom_line(size = 3, alpha = .7) +
  geom_hline(yintercept = .64,##TODO: Calculate from scratch
             linetype = "dotted", color = "red",
             size = 1.2, alpha = .5) + 
  theme_minimal() +
  labs(x = "Layer",
       y = "Best R2",
       color = "") +
  # scale_x_log10() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(9, option = "mako", 
                                                   begin = 0.8, end = 0.15))

# now just some of them, including 14m and 410m
df_best_r2_layer %>%
  filter(mpath %in% c("EleutherAI/pythia-14m", "EleutherAI/pythia-410m","EleutherAI/pythia-2.8b", "EleutherAI/pythia-6.9b")) %>%
  ggplot(aes(x = Layer,
             y = r2,
             color = mpath)) +
  #geom_point(size = 3, alpha = .7) +
  geom_line(size = 3, alpha = .7) +
  geom_hline(yintercept = .64,##TODO: Calculate from scratch
             linetype = "dotted", color = "red",
             size = 1.2, alpha = .5) + 
  theme_minimal() +
  labs(x = "Layer",
       y = "Best R2",
       color = "") +
  # scale_x_log10() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(4, option = "mako", 
                                                   begin = 0.8, end = 0.15))

# Now plot all models, but by layer depth ratio
# Manuscript figure (Fig. 2a)
df_best_r2_layer$zero_idx_layer <- df_best_r2_layer$Layer - 1 #so they all start at layer depth ratio == 0
df_best_r2_layer %>%
  group_by(model) %>%
  mutate(layer_ratio = zero_idx_layer / max(zero_idx_layer)) %>%
  ungroup() %>%
  ggplot(aes(x = layer_ratio,
             y = r2,
             color = reorder(model, n_params))) +
  geom_line(size = 3, alpha = .7) +
  geom_hline(yintercept = 0.64,
             linetype = "dotted", color = "red",
             size = 1.2, alpha = 0.5) +
  theme_minimal() +
  labs(x = "Layer Depth Ratio",
       y = "Best R2",
       color = "") +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(9, option = "mako",
                                                   begin = 0.8, end = 0.15))




summary_df <- df_best_r2_layer %>%
  mutate(binned_prop_layer = ntile(prop_layer, 10)) %>%
  mutate(prop_binned = binned_prop_layer / 10) %>%
  group_by(model, n_params, prop_binned) %>%
  summarise(
    mean_r2 = mean(r2)
  ) 

#layer depth ratio starting with non-zero-indexing of layers
#ggplot(summary_df, aes(x = prop_binned, 
#                       y = mean_r2, 
#                       color = reorder(model, n_params))) +
#  geom_point(size = 3, alpha = .7) +
#  geom_line(size = 1.3, alpha = .7) +
#  geom_hline(yintercept = .64,##TODO: Calculate from scratch
#             linetype = "dotted", color = "red",
#             size = 1.2, alpha = .5) + 
#  labs(x = "Layer Depth",
#       y = "Mean R2",
#       color = "", fill = "") +
#  scale_color_manual(values = viridisLite::viridis(9, option = "mako", 
#                                                   begin = 0.8, end = 0.15)) + 
#  theme_minimal(base_size = 15) +
#  theme(text = element_text(size = 15),
#        legend.position = "bottom")


### Effect of absolute layer?
mod = lmer(data = df_best_r2_layer,
           r2 ~ Layer + (1 |model))
summary(mod)

### Effect of relative layer?
mod = lmer(data = df_best_r2_layer,
           r2 ~ prop_layer_scaled + (1 |model))
summary(mod)

### Independent effects?
mod = lmer(data = df_best_r2_layer,
           r2 ~ prop_layer_scaled + Layer + (1 |model))
summary(mod)
```


## Best R2 by step, only 14m (best layer)

```{r r2_by_step}
df_best_r2_14m = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-14m")) %>%
  group_by(mpath, revision, step, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%
  group_by(mpath, step, n_params) %>%
  slice_max(r2, n = 1) %>%  
  mutate(step_modded = step + 1) %>%
  mutate(million_tokens_seen = 2.1 * step_modded) %>%
  group_by(mpath) %>%
  mutate(
    r2_diff = r2 - lag(r2),
    r2_diff2 = r2_diff - lag(r2_diff)
  )

df_best_r2_14m %>%
  # filter(mpath == "EleutherAI/pythia-14m") %>%
  ggplot(aes(x = step_modded,
             y = r2)) +
  #geom_point(size = 2, alpha = .7) +
  geom_line(size = 3, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dashed", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "none") +
  scale_color_viridis(option = "mako", discrete=TRUE)


df_best_r2_14m %>%
  filter(step > 0) %>%
  ggplot(aes(x = step_modded,
             y = r2_diff,
             color = reorder(mpath, n_params))) +
  geom_point(size = 4, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "R2 change (1st derivative)",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dotted", size = 2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE)


df_best_r2_14m %>%
  filter(step > 0) %>%
  ggplot(aes(x = step_modded,
             y = r2_diff2,
             color = reorder(mpath, n_params))) +
  geom_point(size = 4, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "R2 change (2nd derivative)",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dotted", size = 2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE)


df_best_r2_14m %>%
  #filter(mpath == "EleutherAI/pythia-14m") %>%
  ggplot(aes(x = step_modded,
             y = r2)) +
  geom_point(size = 4, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE)


m_step <- lm(r2 ~ log10(step_modded), 
                  data = df_best_r2_14m)
summary(m_step)

## Now just for Pythia410M
df_best_r2_410m = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-410m")) %>%
  group_by(mpath, revision, step, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%
  group_by(mpath, step, n_params) %>%
  slice_max(r2, n = 1) %>%  
  mutate(step_modded = step + 1) %>%
  mutate(million_tokens_seen = 2.1 * step_modded) %>%
  group_by(mpath) %>%
  mutate(
    r2_diff = r2 - lag(r2),
    r2_diff2 = r2_diff - lag(r2_diff)
  )

df_best_r2_410m %>%
  ggplot(aes(x = step_modded,
             y = r2)) +
  geom_point(size = 2, alpha = .7) +
  geom_line(size = 1.3, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "none") +
  scale_color_viridis(option = "mako", discrete=TRUE)

#Combine the dataframes to see the curves together?
# Vertically concatenate
df_best_r2_14mand410m <- rbind(df_best_r2_14m, df_best_r2_410m)
print(df_best_r2_14mand410m)

df_best_r2_14mand410m %>%
    ggplot(aes(x = step_modded,
             y = r2,
             color=mpath)) +
  #geom_point(size = 2, alpha = .7) +
  geom_line(size = 3, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dashed", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15)) 



```

## Best R2 by step, only 14m (layer 3)

```{r r2_by_step}
df_best_r2_14m = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-14m")) %>%
  group_by(mpath, revision, step, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%
  group_by(mpath, step, n_params) %>%
  filter(Layer == 3) %>%
  mutate(step_modded = step + 1) %>%
  mutate(million_tokens_seen = 2.1 * step_modded) %>%
  group_by(mpath) %>%
  mutate(
    r2_diff = r2 - lag(r2),
    r2_diff2 = r2_diff - lag(r2_diff)
  )

df_best_r2_14m %>%
  # filter(mpath == "EleutherAI/pythia-14m") %>%
  ggplot(aes(x = step_modded,
             y = r2)) +
  geom_point(size = 2, alpha = .7) +
  geom_line(size = 1.3, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "none") +
  scale_color_viridis(option = "mako", discrete=TRUE)


df_best_r2_14m %>%
  filter(step > 0) %>%
  ggplot(aes(x = step_modded,
             y = r2_diff,
             color = reorder(mpath, n_params))) +
  geom_point(size = 4, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "R2 change (1st derivative)",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dotted", size = 2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE)


df_best_r2_14m %>%
  filter(step > 0) %>%
  ggplot(aes(x = step_modded,
             y = r2_diff2,
             color = reorder(mpath, n_params))) +
  geom_point(size = 4, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "R2 change (2nd derivative)",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dotted", size = 2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE)


df_best_r2_14m %>%
  #filter(mpath == "EleutherAI/pythia-14m") %>%
  ggplot(aes(x = step_modded,
             y = r2)) +
  geom_point(size = 4, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE)


m_step <- lm(r2 ~ log10(step_modded), 
                  data = df_best_r2_14m)
summary(m_step)

## Now just for Pythia410M
df_best_r2_410m = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-410m")) %>%
  group_by(mpath, revision, step, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%
  group_by(mpath, step, n_params) %>%
  slice_max(r2, n = 1) %>%  
  mutate(step_modded = step + 1) %>%
  mutate(million_tokens_seen = 2.1 * step_modded) %>%
  group_by(mpath) %>%
  mutate(
    r2_diff = r2 - lag(r2),
    r2_diff2 = r2_diff - lag(r2_diff)
  )

df_best_r2_410m %>%
  ggplot(aes(x = step_modded,
             y = r2)) +
  geom_point(size = 2, alpha = .7) +
  geom_line(size = 1.3, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "none") +
  scale_color_viridis(option = "mako", discrete=TRUE)

#Combine the dataframes to see the curves together?
# Vertically concatenate
df_best_r2_14mand410m <- rbind(df_best_r2_14m, df_best_r2_410m)
print(df_best_r2_14mand410m)

df_best_r2_14mand410m %>%
    ggplot(aes(x = step_modded,
             y = r2,
             color=mpath)) +
  #geom_point(size = 2, alpha = .7) +
  geom_line(size = 3, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dashed", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15)) 



```



## Best R2 by step, multiple models (best layer at final checkpoint)

```{r r2_by_step}
TARGET_REVISIONS = c(0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1000, 
                     2000, 5000, 10000, 25000, 50000, 
                     # 51000, # For 12B
                     75000, 100000, 143000)


### Get best R2 at final layer
df_best_r2_layer = df_pythia_models %>% 
  filter(step == 143000) %>%
  filter(Layer > 0) %>%
  group_by(mpath, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%  
  mutate(model = sub("^EleutherAI/", "", mpath)) %>%
  group_by(model) %>%
  slice_max(r2, n = 1, with_ties = FALSE) %>%
  dplyr::select(model, Layer) 


df_best_r2 = df_pythia_models %>% 
  filter(Layer > 0) %>%
  # filter(mpath %in% c("EleutherAI/pythia-14m")) %>%
  group_by(mpath, revision, step, Layer, n_params) %>%
  summarise(r = cor(Distance, mean_relatedness, method = "pearson"),
            r2 = r ** 2) %>%
  mutate(step_modded = step + 1) %>%
  mutate(model = sub("^EleutherAI/", "", mpath)) %>%
  filter(step %in% TARGET_REVISIONS) %>%
  inner_join(df_best_r2_layer) %>%
  group_by(mpath) %>%
  mutate(
    r2_diff = r2 - lag(r2),
    r2_diff2 = r2_diff - lag(r2_diff)
  )


df_best_r2 %>%
  ggplot(aes(x = step_modded,
             y = r2,
             color = reorder(model, n_params))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 1, alpha = .7, linetype = "dashed") +
  geom_hline(yintercept = .64,##TODO: Calculate from scratch
             linetype = "dotted", color = "red",
             size = 1.2, alpha = .5) + 
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Best R2",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(9, option = "mako", 
                                                   begin = 0.8, end = 0.15))



df_best_r2 %>%
  ggplot(aes(x = step_modded,
             y = r2_diff,
             color = reorder(model, n_params))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 1.3, alpha = .7) +
  geom_hline(yintercept = 0,
             linetype = "dotted", color = "black",
             size = 1.2, alpha = .5) + 
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "R2 Diff",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(9, option = "mako", 
                                                   begin = 0.8, end = 0.15))



```




