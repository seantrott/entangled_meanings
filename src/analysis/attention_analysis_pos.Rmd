---
title: "Analysis of Alternative Sentence Frames"
author: "Sean Trott and Pam Rivi√®re"
date: "November 20, 2024"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dpi = 300, fig.format = "png")
```


```{r include=FALSE}
library(tidyverse)
library(lmtest)
library(forcats)
library(broom)
library(lme4)
library(viridis)
library(ggridges)
library(lmerTest)
library(ggrepel)
library(ggcorrplot)

all_colors <- viridis::viridis(10, option = "mako")
my_colors <- all_colors[c(3, 5, 7)]  # Selecting specific colors from the palette
```

# Load Pythia data


Here, we analyze data looking at the average attention each head gives from the ambiguous token to the disambiguating token.

```{r}
# setwd("/Users/seantrott/Dropbox/UCSD/Research/Ambiguity/SSD/entangled_meanings/src/analysis/")
directory_path <- "../../data/processed/rawc/pythia/attention_pos_check/"
csv_files <- list.files(path = directory_path, pattern = "*.csv", full.names = TRUE)
csv_list <- csv_files %>%
  map(~ read_csv(.))
df_pythia_models <- bind_rows(csv_list) %>%
  mutate(Layer = Layer + 1,
         Head = Head + 1)

table(df_pythia_models$mpath)

```



# Analysis of 14m

## Final step

```{r}
df_final_step = df_pythia_models %>%
  filter(mpath == "EleutherAI/pythia-14m") %>%
  filter(step == 143000)
nrow(df_final_step)

df_attn_by_head = df_final_step %>%
  group_by(mpath, Layer, Head, n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  group_by(mpath) %>%
  mutate(max_layer = max(Layer),
         prop_layer = Layer / max_layer) %>%
  mutate(binned_prop_layer = ntile(prop_layer, 6)) %>%
  mutate(prop_binned = binned_prop_layer / 6) 


df_attn_by_head %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = mean_attention)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Attention to Disambiguating Word") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Attention to Disambiguating Word") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") +
  facet_wrap(~class_ambiguous_word)


```



## Attention by head

```{r}
df_attention_over_time = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-14m")) %>%
  group_by(mpath, revision, Layer, Head, step, n_params) %>%
  summarise(mean_attention = mean(Attention)) %>%
  mutate(step_modded = step + 1) %>%
  group_by(mpath, step, Head)

df_attention_over_time %>%
  # filter(Layer == 3) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~Layer)

df_attention_over_time = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-14m")) %>%
  group_by(mpath, revision, Layer, Head, step, 
           n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  mutate(step_modded = step + 1) %>%
  group_by(mpath, step, Head)

df_attention_over_time %>%
  # filter(Layer == 6) %>%
  # filter(Head %in% c(1, 2)) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~Layer + class_ambiguous_word)

df_attention_over_time %>%
  filter(Layer == 6) %>%
  # filter(Head %in% c(1, 2)) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head (Layer 6)") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~class_ambiguous_word)

```


# Analysis of 410m

## Final step

```{r}
df_final_step = df_pythia_models %>%
  filter(mpath == "EleutherAI/pythia-410m") %>%
  filter(step == 143000)
nrow(df_final_step)

df_attn_by_head = df_final_step %>%
  group_by(mpath, Layer, Head, n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  group_by(mpath) %>%
  mutate(max_layer = max(Layer),
         prop_layer = Layer / max_layer) %>%
  mutate(binned_prop_layer = ntile(prop_layer, 6)) %>%
  mutate(prop_binned = binned_prop_layer / 6) 


df_attn_by_head %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = mean_attention)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Attention to Disambiguating Word") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Attention to Disambiguating Word") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") +
  facet_wrap(~class_ambiguous_word)


### Top heads
df_attn_by_head %>%
  arrange(desc(mean_attention)) %>%
  dplyr::select(Layer, Head, class_ambiguous_word, mean_attention) %>%
  head(10)

```


## POS-agnostic heads?

```{r}
df_attn_by_head_wide = df_attn_by_head %>%
  pivot_wider(names_from = class_ambiguous_word,
              values_from = mean_attention) %>%
  mutate(diff = N - V,
         min_attn = pmin(N, V))

write.csv(df_attn_by_head_wide, "../../data/processed/rawc/pythia/summaries/attn_diff_410m.csv")

df_attn_by_head_wide %>%
  ggplot(aes(x = N,
             y = V)) +
  geom_point(alpha = .5) +
  labs(x = "Attention to disambiguating nouns",
       y = "Attention to disambiguating verbs") +
  theme_minimal()




df_attn_by_head_wide %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = min_attn)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Min. Attn. Across POS") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Min. Attn. Across POS") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") 

df_attn_by_head_wide %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = diff)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Attn. Diff. (N - V)") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Attn. Diff. (N - V)") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") 



### Top "agnostic" heads
df_attn_by_head_wide %>%
  arrange(desc(min_attn)) %>%
  dplyr::select(Layer, Head, N, V) %>%
  head(10)

### Top "specific" heads
df_attn_by_head_wide %>%
  arrange(desc(abs(diff))) %>%
  dplyr::select(Layer, Head, N, V, diff) %>%
  head(10)
```




## Attention over time

```{r}

df_attention_over_time = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-410m")) %>%
  group_by(mpath, revision, Layer, Head, step, 
           n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  mutate(step_modded = step + 1) %>%
  group_by(mpath, step, Head)

df_attention_over_time %>%
  filter(Layer %in% c(1, 2, 4, 6, 22, 23)) %>%
  # filter(Head %in% c(1, 2)) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~Layer + class_ambiguous_word)

```


