---
title: "Analysis of Alternative Sentence Frames"
author: "Sean Trott and Pam Rivi√®re"
date: "November 20, 2024"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dpi = 300, fig.format = "pdf")
```


```{r include=FALSE}
library(tidyverse)
library(lmtest)
library(forcats)
library(broom)
library(lme4)
library(viridis)
library(ggridges)
library(lmerTest)
library(ggrepel)
library(ggcorrplot)

all_colors <- viridis::viridis(10, option = "mako")
my_colors <- all_colors[c(3, 5, 7)]  # Selecting specific colors from the palette
```

# Load Pythia data


Here, we analyze data looking at the average attention each head gives from the ambiguous token to the disambiguating token.

```{r}
# setwd("/Users/seantrott/Dropbox/UCSD/Research/Ambiguity/SSD/entangled_meanings/src/analysis/")
directory_path <- "../../data/processed/rawc/pythia/attention_pos_check/"
csv_files <- list.files(path = directory_path, pattern = "*.csv", full.names = TRUE)
csv_list <- csv_files %>%
  map(~ read_csv(.))
df_pythia_models <- bind_rows(csv_list) %>%
  mutate(Layer = Layer + 1,
         Head = Head + 1)

table(df_pythia_models$mpath)

```



# Analysis of 14m

## Final step

```{r}
df_final_step = df_pythia_models %>%
  filter(mpath == "EleutherAI/pythia-14m") %>%
  filter(step == 143000)
nrow(df_final_step)

df_attn_by_head = df_final_step %>%
  group_by(mpath, Layer, Head, n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  group_by(mpath) %>%
  mutate(max_layer = max(Layer),
         prop_layer = Layer / max_layer) %>%
  mutate(binned_prop_layer = ntile(prop_layer, 6)) %>%
  mutate(prop_binned = binned_prop_layer / 6) 


df_attn_by_head %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = mean_attention)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Attention to Disambiguating Word") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Attention to Disambiguating Word") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") +
  facet_wrap(~class_ambiguous_word)


```



## Attention by head

```{r}
df_attention_over_time = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-14m")) %>%
  group_by(mpath, revision, Layer, Head, step, n_params) %>%
  summarise(mean_attention = mean(Attention)) %>%
  mutate(step_modded = step + 1) %>%
  group_by(mpath, step, Head)

df_attention_over_time %>%
  # filter(Layer == 3) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~Layer)

df_attention_over_time = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-14m")) %>%
  group_by(mpath, revision, Layer, Head, step, 
           n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  mutate(step_modded = step + 1) %>%
  group_by(mpath, step, Head)

df_attention_over_time %>%
  # filter(Layer == 6) %>%
  # filter(Head %in% c(1, 2)) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~Layer + class_ambiguous_word)

df_attention_over_time %>%
  filter(Layer == 6) %>%
  # filter(Head %in% c(1, 2)) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head (Layer 6)") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~class_ambiguous_word)

```


# Analysis of 410m

## Final step

```{r}
df_final_step = df_pythia_models %>%
  filter(mpath == "EleutherAI/pythia-410m") %>%
  filter(step == 143000)
nrow(df_final_step)

df_attn_by_head = df_final_step %>%
  group_by(mpath, Layer, Head, n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  group_by(mpath) %>%
  mutate(max_layer = max(Layer),
         prop_layer = Layer / max_layer) %>%
  mutate(binned_prop_layer = ntile(prop_layer, 6)) %>%
  mutate(prop_binned = binned_prop_layer / 6) 


df_attn_by_head %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = mean_attention)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Attention to Disambiguating Word") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Attention to Disambiguating Word") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") +
  facet_wrap(~class_ambiguous_word)


### Top heads
df_attn_by_head %>%
  arrange(desc(mean_attention)) %>%
  dplyr::select(Layer, Head, class_ambiguous_word, mean_attention) %>%
  head(10)

```


## POS-agnostic heads?

```{r}
df_attn_by_head_wide = df_attn_by_head %>%
  pivot_wider(names_from = class_ambiguous_word,
              values_from = mean_attention) %>%
  mutate(diff = N - V,
         min_attn = pmin(N, V))

write.csv(df_attn_by_head_wide, "../../data/processed/rawc/pythia/summaries/attn_diff_410m.csv")

df_attn_by_head_wide %>%
  ggplot(aes(x = N,
             y = V)) +
  geom_point(alpha = .5) +
  labs(x = "Attention to disambiguating nouns",
       y = "Attention to disambiguating verbs") +
  theme_minimal()




df_attn_by_head_wide %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = min_attn)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Min. Attn. Across POS") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Min. Attn. Across POS") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") 

df_attn_by_head_wide %>%
  ggplot(aes(x = Layer,
             y = Head,
             fill = diff)) +
  geom_tile() +
  labs(x = "Layer",
       y = "Head",
       fill = "Attn. Diff. (N - V)") +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "red",
                       midpoint = 0, 
                       name = "Attn. Diff. (N - V)") +
  theme_minimal() +
  theme(text = element_text(size = 15),
        strip.text.y = element_text(angle = 0), # Keep facet labels horizontal
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom") 



### Top "agnostic" heads
df_attn_by_head_wide %>%
  arrange(desc(min_attn)) %>%
  dplyr::select(Layer, Head, N, V) %>%
  head(10)

### Top "specific" heads
df_attn_by_head_wide %>%
  arrange(desc(abs(diff))) %>%
  dplyr::select(Layer, Head, N, V, diff) %>%
  head(10)
```


## Correlating with other stress tests

### Loading data

```{r}

### R2 ~ Attention to disambiguation word
regression_results_df = read_csv("../../data/processed/rawc/pythia/summaries/r2_results_410m.csv") %>%
  select(-`...1`)

### Subtraction results
t_test_results_subset = read_csv("../../data/processed/rawc/pythia/summaries/t_test_results.csv") %>%
  select(-`...1`) %>%
  filter(step ==143000) %>%
  select(Layer, Head , t_statistic, p_adjusted) %>%
  mutate(Head = Head + 1) ### To match others


### Sort of
df_attn_sortof = read_csv("../../data/processed/rawc/pythia/summaries/sortof_410m.csv") %>%
  select(-`...1`) %>%
  select(attn_disamb_sort_of, Layer, Head)


### POS agnostic
df_attn_by_head_wide = read_csv("../../data/processed/rawc/pythia/summaries/attn_diff_410m.csv") %>%
  select(-`...1`) %>%
  select(N, V, diff, min_attn, Layer, Head)


### Joining
df_ttest_r2_attns = df_attn_by_head_wide %>%
  inner_join(regression_results_df) %>%
  inner_join(t_test_results_subset) %>%
  inner_join(df_attn_sortof)

nrow(df_ttest_r2_attns)
```


### Analysis

```{r}

### Now look at relationships

df_ttest_r2_attns$is_sig = df_ttest_r2_attns$p_adjusted < .05

df_ttest_r2_attns %>%
  mutate(Coefficient_floor = ifelse(Coefficient > 0, Coefficient, 0)) %>%
  mutate(
    t_test_floor = ifelse(t_statistic > 0, t_statistic, 0),
    label = ifelse(Coefficient_floor > 0 & t_test_floor > 0 & is_sig == TRUE,
                   paste(Layer, Head, sep = "_"),
                   NA)
  ) %>%
  ggplot(aes(x = Coefficient_floor,
             y = t_test_floor,
             color = is_sig)) +
  geom_point(size = 3, alpha = .5) +
  theme_minimal() +
  geom_hline(yintercept = 0 ,linetype = "dotted") +
  geom_text_repel(aes(label = label), size = 4) +
  geom_vline(xintercept = 0 ,linetype = "dotted") +
    scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15)) +
  labs(x = "Coefficient (R2 ~ Attention)",
       y = "t-statistic (1-back analysis)") +
  theme(text = element_text(size = 15),
        legend.position = "none")


df_ttest_r2_attns %>%
  mutate(Coefficient_floor = ifelse(Coefficient > 0, Coefficient, 0)) %>%
  mutate(
    t_test_floor = ifelse(t_statistic > 0, t_statistic, 0),
    label = ifelse(Coefficient_floor > 0 & t_test_floor > 0 & is_sig == TRUE,
                   paste(Layer, Head, sep = "_"),
                   NA)
  ) %>%
  ggplot(aes(x = Coefficient_floor,
             y = min_attn,
             color = is_sig)) +
  geom_point(size = 3, alpha = .5) +
  theme_minimal() +
  geom_hline(yintercept = 0 ,linetype = "dotted") +
  geom_text_repel(aes(label = label), size = 4) +
  geom_vline(xintercept = 0 ,linetype = "dotted") +
    scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15)) +
  labs(x = "Coefficient (R2 ~ Attention)",
       y = "Min. Attn. Across POS") +
  theme(text = element_text(size = 15),
        legend.position = "none")


```

### PCA to identify disambiguation axis

```{r}
pca_features <- df_ttest_r2_attns %>%
  select(Coefficient, t_statistic, is_sig, N, V, attn_disamb_sort_of) %>%
  scale()  # Standardize

pca_result <- prcomp(pca_features, center = TRUE, scale. = TRUE)
summary(pca_result)  # Check variance explained


#### SCreep lot
explained_var <- pca_result$sdev^2
explained_var_ratio <- explained_var / sum(explained_var)
scree_df <- data.frame(
  PC = paste0("PC", seq_along(explained_var_ratio)),
  Variance_Explained = explained_var_ratio
)

ggplot(scree_df, aes(x = PC, y = Variance_Explained)) +
  geom_col(fill = "steelblue") +
  geom_line(aes(group = 1), color = "black") +
  geom_point() +
  theme_minimal() +
  labs(title = "Scree Plot",
       x = "Principal Component",
       y = "Proportion of Variance Explained") +
  scale_y_continuous(labels = scales::percent_format())


### Look at loadings
loadings_df <- as.data.frame(pca_result$rotation)
loadings_df$feature <- rownames(loadings_df)

loadings_long <- loadings_df %>%
  pivot_longer(cols = starts_with("PC"),
               names_to = "PC",
               values_to = "Loading")


ggplot(loadings_long, aes(x = PC, y = feature, fill = Loading)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red",
                       midpoint = 0) +
  theme_minimal() +
  labs(title = "PCA Loadings Heatmap",
       x = "Principal Component",
       y = "Original Feature")


### Look at distribution
df_ttest_r2_attns <- df_ttest_r2_attns %>%
  mutate(disambig_PC1 = pca_result$x[,1])

### Labeling bottom 1% of PC1
df_ttest_r2_attns %>%
  mutate(label = ifelse(disambig_PC1 <= quantile(disambig_PC1, .01),
                        paste(Layer, Head, sep = "_"),
                        NA)) %>%
  ggplot(aes(x = disambig_PC1)) +
  geom_vline(xintercept = 0, linetype = "dotted") +
  geom_text_repel(aes(label = label, y = 0), 
                  size = 3.5,
                  nudge_y = 5, 
                  direction = "x", 
                  segment.color = "grey50",
                  na.rm = TRUE) +
  geom_histogram(bins = 30, alpha = .5) +
  theme_minimal() +
  labs(title = "PC1: Disambiguation Head Axis")


df_ttest_r2_attns %>%
  mutate(label = ifelse(disambig_PC1 <= quantile(disambig_PC1, 0.05) & is_sig == TRUE,
                        paste(Layer, Head, sep = "_"),
                        NA)) %>%
  ggplot(aes(x = attn_disamb_sort_of,
             y = disambig_PC1,
             color = is_sig)) +
  geom_point(size = 3, alpha = .5) +
  theme_minimal() +
  geom_hline(yintercept = 0 ,linetype = "dotted") +
  geom_text_repel(aes(label = label), size = 4) +
  geom_vline(xintercept = 0 ,linetype = "dotted") +
    scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15)) +
  labs(x = "Mean Attn. (Sort Of Analysis)",
       y = "PC 1") +
  theme(text = element_text(size = 15),
        legend.position = "none")


```




## Attention over time

```{r}

df_attention_over_time = df_pythia_models %>% 
  filter(mpath %in% c("EleutherAI/pythia-410m")) %>%
  group_by(mpath, revision, Layer, Head, step, 
           n_params, class_ambiguous_word) %>%
  summarise(mean_attention = mean(Attention)) %>%
  mutate(step_modded = step + 1) %>%
  group_by(mpath, step, Head)

df_attention_over_time %>%
  filter(Layer %in% c(1, 2, 4, 6, 22, 23)) %>%
  # filter(Head %in% c(1, 2)) %>%
  ggplot(aes(x = step_modded,
             y = mean_attention,
             color = factor(Head))) +
  geom_point(size = 3, alpha = .7) +
  geom_line(size = 2, alpha = .7) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Attention to Disambiguating Word",
       color = "Attention Head") +
  scale_x_log10() +
    geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_viridis(option = "mako", discrete=TRUE) +
  facet_wrap(~Layer + class_ambiguous_word)

```


